\chapter{実装}
\label{chap:zisso}

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{実装環境}
本研究での実装環境は下記である. 

\begin{itemize}
 \item オペレーティングシステム
    \begin{itemize}
      \item Mac OS Ventura 13.4.1
    \end{itemize}
 \item 実装言語
    \begin{itemize}
      \item Python 3.11.6
    \end{itemize}
\end{itemize}

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{スクレイピング}\label{scraping}
\subsection{Google Playストアのスクレイピング}
本研究で取得するレビュー情報は先行研究\cite{kawatsura}に合わせて下記とする. 

\begin{itemize}
 \item reviewId : レビューID
 \item userName : ユーザ名
 \item userImage : ユーザのプロフィール画像
 \item at : 投稿日時
 \item score : 星の数
 \item content : レビュー内容
 \item thumbsUpCount : このレビューが参考になったと評価した人の数
 \item reviewCreatedVersion : レビュー時のバージョン
 \item replyContent : 開発者からの返信の内容
 \item repliedAt : 開発者からの返信日時
\end{itemize}

先行研究では投稿日時が2021年10月21日〜2021年12月15日までの8週間のレビューを収集している. 収集されたGoogle Playストアの各アプリのレビュー数は表\ref{tb:rawreviewnum}の通りである. 
\begin{table}[H]
  \caption{収集したGoogle Playストアのレビュー数 (2021/10/21〜12/15) （ \cite{kawatsura} p.16, 表 4.2）}
  \label{tb:rawreviewnum}
  \begin{center}
  \begin{tabular}{l|r}
    \hline
    アプリ名&収集したレビュー数（件）\\\hline\hline
    にゃんトーク&171\\\hline
    スマートニュース&1,651\\\hline
    PayPay&1,052\\\hline
    Coke ON&1,736\\\hline
    Google Fit&372\\\hline
    Simeji&468\\\hline
    Lemon8&72\\\hline
    楽天ペイ&480\\\hline
    majica&706\\\hline
    LINE MUSIC&359\\\hline
    BuzzVideo&375\\\hline
    ファミマのアプリ&290\\\hline
    CapCut&180\\\hline\hline
    合計&7,912
  \end{tabular}\end{center}
\end{table}

\noindent
この先行研究のデータに加え, 本研究では2023年10月1日〜12月22日のレビューを新たに取得する. 新たに取得されたGoogle Playストアの各アプリのレビュー数は表\ref{tb:rawreviewnum2023}の通りである. 
\begin{table}[H]
  \caption{収集したGoogle Playストアのレビュー数 (2023/10/1〜12/22) }
  \label{tb:rawreviewnum2023}
  \begin{center}
  \begin{tabular}{l|r}
    \hline
    アプリ名&収集したレビュー数（件）\\\hline\hline
    にゃんトーク&11\\\hline
    スマートニュース&531\\\hline
    PayPay&700\\\hline
    Coke ON&840\\\hline
    Google Fit&192\\\hline
    Simeji&164\\\hline
    Lemon8&122\\\hline
    楽天ペイ&606\\\hline
    majica&128\\\hline
    LINE MUSIC&115\\\hline
    ファミマのアプリ&295\\\hline
    CapCut&263\\\hline\hline
    合計&3,967
  \end{tabular}\end{center}
\end{table}

Google PlayストアのレビューをスクレイピングするためにPythonのプログラムである\verb|get_google_play_review.py|を作成した. このプログラムでは, アプリのパッケージ名を与えると, そのアプリのレビュー情報をcsv形式で保存するよう実装となっている. 
レビューのスクレイピングのために, Pythonのライブラリであるgoogle-play-scraperを使用する. google-play-scraperでは外部依存関係なしでPython用のGoogle Playストアを簡単にクロールするためのAPIが提供されている\cite{google-play-scraper}. 
このライブラリを使用することにより, アプリのパッケージ名, 言語, 取得する数, 順序を指定してレビューの一覧を取得することができる. 

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\subsection{Twitterのスクレイピング}
\label{sec:x}
本研究で取得するツイート情報は先行研究\cite{kawatsura}に合わせて下記とする. 
\begin{itemize}
 \item id : ツイートID
 \item content : ツイート内容
 \item at : ツイート日時
\end{itemize}

先行研究では投稿日時が2021年10月21日〜2021年12月15日までの8週間のツイートを収集している. 収集されたTwitterの各アプリのツイート数を表\ref{tb:rawtweetnum}に示す. 

\begin{table}[H]
  \caption{収集したTwitterのツイート数 (2021/10/21〜12/15) （ \cite{kawatsura} p.18, 表 4.3）}
  \label{tb:rawtweetnum}
  \begin{center}
  \begin{tabular}{l|r}
    \hline
    アプリ名&収集したツイート数（件）\\\hline\hline
    にゃんトーク&2,525\\\hline
    スマートニュース&50,590\\\hline
    PayPay&880,319\\\hline
    Coke ON&84,424\\\hline
    Google Fit&13,496\\\hline
    Simeji&205,327\\\hline
    Lemon8&4,376\\\hline
    楽天ペイ&11,111\\\hline
    majica&3,649\\\hline
    LINE MUSIC&184,873\\\hline
    BuzzVideo&41,656\\\hline
    ファミマのアプリ&8,867\\\hline
    CapCut&33,998\\\hline\hline
    合計&1,525,211
  \end{tabular}\end{center}
\end{table}

\noindent
先行研究で得たデータに加え, 本研究では新たに2023年10月1日から2023年12月22日のツイートを取得する. Twitterのツイート取得に関してはTwitter APIを使用してスクレイピングを行う. Twitter APIのプランに関してはFree, Basic, Pro, Enterpriseの4つのプランが用意されておりそれぞれ料金や使用できる機能などが異なる. 大規模なサービスやビジネス向けのEnterpriseプラン以外の3つのプランの違いの一部を表\ref{tb:xplan}に示す. 
表\ref{tb:xplan}よりツイートを取得するためにはBasicプラン以上に加入する必要がある. Basicプランに加入した場合でも合計で30,000件しか取得できないため本研究では先行研究のデータセットを追加で使用することとした. Twitterの利用規約によると, Twitterが提供するインターフェイスを介して行うスクレイピング以外は禁止としている. そのため, seleniumなどを使用したスクレイピングはせずに, 先行研究のデータを使用することとした. 

\begin{table}[H]
  \caption{プランとできること}
  \label{tb:xplan}
  \begin{center}
  \begin{tabular}{l|c|c|c}
    \hline
    &Free&Basic&Pro \\\hline\hline
    料金&無料&月額100ドル&月額5,000ドル \\\hline
    月間ツイート数の上限&1,500&3,000&300,000 \\\hline
    月間ツイート取得数&0&10,000&1,000,000 \\\hline
  \end{tabular}\end{center}
\end{table}

Twitter APIを使用してツイートを取得するためにPythonのプログラムである\verb|get_tweet.py|を作成した. このプログラムではTwitter APIにアクセスするためのライブラリであるTweepy\cite{tweepy}を使用した. まずAPIキーなどの4つの認証情報をセットする. 次にClientクラスのsearch\_resent\_tweetメソッドを使用してツイートを取得する. 
このメソッドは最大で過去7日間まで遡ってツイートを取得できる. search\_all\_tweetsメソッドでは全てのツイートを取得できるが, Academic Researchアクセスの利用資格があるものしか使用できないメソッドである. このアクセスを利用するにはAcademic Research申請を提出する必要があり, ``修士課程の学生, 博士号取得候補者, 博士研究員, 大学教員, 学術機関または大学の研究員である''ことが申し込みをする1つの条件となっている. \cite{academic-research}
私は申し込みの条件を満たしていないため, このメソッドは使用しなかった. 
先行研究と同じ情報を取得するために, 本研究では引数として次に示すものを与えた. 
\begin{itemize}
 \item max\_result : 検索結果の最大数. 10〜100の数値で, デフォルトは10
 \item query: 検索ワード
 \item tweet\_field: リスト形式でツイートフィールドを選択. 今回はツイート日時を取得するために["created\_at"]とした. 
 \item end\_time: 期間の終わりを指定できる (UTCタイムスタンプ) 
\end{itemize}
新たに取得したTwitterのツイート数を表\ref{tb:rawtweetnum2023}に示す

\begin{table}[H]
  \caption{収集したTwitterのツイート数 (2023/10/1〜12/22) }
  \label{tb:rawtweetnum2023}
  \begin{center}
  \begin{tabular}{l|r}
    \hline
    アプリ名&収集したツイート数（件）\\\hline\hline
    にゃんトーク&27\\\hline
    スマートニュース&2,575\\\hline
    PayPay&3,297\\\hline
    Coke ON&2,595\\\hline
    Google Fit&2,760\\\hline
    Simeji&2,579\\\hline
    Lemon8&2,593\\\hline
    楽天ペイ&2,591\\\hline
    majica&2.596\\\hline
    LINE MUSIC&2,580\\\hline
    ファミマのアプリ&2,575\\\hline
    CapCut&2,592\\\hline\hline
    合計&29,360
  \end{tabular}\end{center}
\end{table}

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{前処理}\label{preprocessing}
機械学習によるレビューに含まれる有用な箇所の自動抽出における精度を上げるために, Google PlayストアとTwitterから取得したデータに対して前処理を行うプログラム (\verb|preprocessing_google.py|, \verb|preprocessing_twitter.py|) を作成した. このプログラムでは次に示す処理を行う. 処理は一般的な自然言語処理の手法を参考としている. 
\begin{itemize}
  \item 英語を全て小文字に揃える
  \item 次に示すの文字列を削除
    \begin{itemize}
      \item 「」【】（） () 『』
      \item @＠から始まるメンション
      \item \#から始まるタグ
      \item URL
      \item 半角空白，全角空白
      \item 絵文字
      \item 日本語を含まないレビュー
    \end{itemize}
  \item レビューやツイートには, 異なる欠陥の報告やアプリに対する要望に関する文が2文以上からなるものがある. そのため, 「。」「.」「！」「!」「？」「!」「\verb|\n|」「\verb|\r\n|」でそれぞれの文に分割する. 
\end{itemize}
図\ref{fig:preprocessing}がレビューを前処理した例である. 2つの文で構成されているため「。」で区切り分割している. また絵文字は削除されている. 

\begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]
      {contents/images/preprocessing.png}
 \caption{前処理の例\label{fig:preprocessing}}
\end{figure}

最後に, 前処理した結果をcsvファイルにて保存する. 保存する項目は, 投稿日時 (at) , レビューのid (reviewId) またはツイートid (id) , そして, 前処理した文章である. 
% 図\ref{tb:googlecsv}, 図\ref{tb:twittercsv}に前処理結果後のcsvファイルの一部を示す. 

% \begin{table}[H]
%   \caption{Google Playストアレビューの前処理結果 (buzzvideo) }
%   \label{tb:googlecsv}
%   \begin{center}
%   \begin{tabularx}{\linewidth}{|l|l|X|}
%     \hline
%     at&reviewId&content\\\hline\hline
%     2021-12-15 19:25:30&gp:AOqpTOHj6w ...&バズビデオを見て、感動をありがとう\\\hline
%     2021-12-15 12:28:09&gp:AOqpTOHleV ...&内容が残酷で異常な人が多い\\\hline
%     2021-12-15 11:09:50&gp:AOqpTOHG7O ...&分かりづらい\\\hline
%     2021-12-14 15:16:33&gp:AOqpTOGWvT ...&ばず29さいって人が投稿してる動画すべて虚偽動画なのでアカウント削除と動画削除して欲しい\\\hline
%     2021-12-14 15:16:33&gp:AOqpTOGWvT ...&あるだけで大迷惑です\\\hline
%     2021-12-14 15:16:33&gp:AOqpTOGWvT ...&二度と登録し直せないよう個体識別番号で縛ってください\\\hline
%     2021-12-14 15:16:33&gp:AOqpTOGWvT ...&お願いします\\\hline
%   \end{tabularx}\end{center}
% \end{table}

% \begin{table}[H]
%   \caption{ツイートの前処理結果 (BuzzVideo) }
%   \label{tb:twittercsv}
%   \begin{center}
%   \begin{tabularx}{\linewidth}{|l|l|X|}
%     \hline
%     at&id&content\\\hline\hline
%     2021-12-15T23:55:11.000Z&1471267626655825922&芸能人に似てる気がするけど名前が思い出せない\\\hline
%     2021-12-15T23:53:43.000Z&1471267256659509249&驚愕男性が豆乳を飲むべき3つの理由\\\hline
%     2021-12-15T23:53:43.000Z&1471267256659509249&男だからこそ注目したい豆乳のメリットとは\\\hline
%     2021-12-15T23:53:17.000Z&1471267149746679813&感情を乗せた歌声と歌詞に聞き惚れちゃう♪壊れかけのradio\\\hline
%     2021-12-15T23:53:10.000Z&1471267120264904705&kkと眞子の酷い嘘\\\hline
%     2021-12-15T23:53:10.000Z&1471267120264904705&恐ろしい真実が明らかに\\\hline
%   \end{tabularx}\end{center}
% \end{table}

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{有用な箇所の自動抽出}\label{extraction}
\subsection{データセット}\label{dataset}
モデルのファインチューニングに使用されるデータセットとして, Google PlayストアとTwitterのツイートからそれぞれ5,000件ずつ合計で10,000件のデータをランダムに抽出し手作業で有用な箇所を抽出した. データセットの作成は情報工学科の学部4年生2人がそれぞれ手作業で行い, お互いの抽出した箇所が異なっていたものは議論することにより統一した. 
データセットには前処理したデータが格納されたcsvファイルを利用して, 抽出したキーフレーズを含めた新たなcsvファイルを作成する. 作成されたcsvファイルにはid,アプリ名,投稿日時,本文, 抽出したキーフレーズの5つのデータが入っている. idは前処理したデータを識別するために与えられ, Google Playストアのレビューはg\_ (index) , Twitterのツイートのidはt\_ (index) とする.  indexには各データに応じた番号が振られている. 
10,000件のデータセットのうち, 6,000件を訓練データ, 2,000件を検証用データ, 2,000件をテストデータとする. 質問応答形式のファインチューニングを行うために, csv形式であるデータセットをソースコード\ref{json}に示すようにjson形式に変換する. 

\begin{lstlisting}[caption=データセット.json,label=json]
  {
    "version": "v2.0", 
    "data": [
      {
        "title": "モバイルアプリのレビュー", 
        "paragraphs": [
          {
            "context": "本アカウントのフォローやリツイートお願いします",
            "qas": [
              {
                "id": "t_2223388",
                "question": "この文はTwitterのツイートです。
                             paypayアプリの欠陥やpaypayアプリに対する
                             要望が書かれているのはどこですか？",
                "is_impossible": true,
                "plausible_answers": [{"text": "", "answer_start": -1}],
                "answers": [{"text": "", "answer_start": -1}]
              }
            ]
          },
          {
            "context": "11/25前後からアプリを開いても強制終了、
                      会員バーコードもクーポンも何も出せない状態、
                      これでは買い物ができないと、こちらのレビュー
                      を見に来て沢山の方が同じ状態であることが
                      わかった",
            "qas": [
              {
                "id": "g_6041", 
                "question": "この文章はGooglePlayストアのレビューです。
                            majicaアプリの欠陥やmajicaアプリに対する
                            要望が書かれているのはどこですか？",
                "answers": [{"text": "アプリを開いても強制終了、
                                      会員バーコードもクーポン
                                      も何も出せない", 
                             "answer_start": -1}], 
                "is_impossible": false
              }
            ]
          }, ...
        ]
      }
    ]
  } 
\end{lstlisting}
\noindent
このjsonファイルは下記の要素によって構成である. 

\begin{itemize}
  \item version: バージョンを表す. 今回は答えられない質問を含むSQuAD 2.0と同じバージョンのため, v2.0とする. SQuAD 2.0とは, スタンフォード質問回答データセットであり質問応答タスクで一般的に使用されているデータセットである. 
  \item title: contextのタイトル
  \item paragraphs: context 1つとそれに関連する質問, 答えがリスト形式で保持されている
  \item qas: 質問と回答がリスト形式となっている
  \item context: 元の文章 (抽出する前の文章) 
  \item id: 設定したid
  \item question: 質問文
  \item is\_impossible: 答えられない質問ならtrue, それ以外はfalse
  \item plausible\_answers: 質問が答えられない時のみ存在し, 問題文から答えになりうる部分を抽出
  \item answers: contextから抜き出した答えとその位置情報がリスト形式で保持されている. 答えを複数用意することもできる. 
  \item text: contextから抜き出した答えのテキスト情報 (抽出する文章) 
  \item answer\_start: contextから抜き出した答えの位置情報
\end{itemize}

\subsection{モデルのファインチューニング}
用意したデータセットを用いて事前学習済みモデルをファインチューニングする. 本研究では事前学習済みモデルとしてHugging FaceのTransformersを通して利用できる東北大学のモデル\cite{tohoku}を使用する. このモデルは日本語のWikipediaのデータを用いて学習されている\cite{tohoku}. 
この東北大学が公開している日本語BERTのうち, whole word maskingを適用して学習させているモデル\cite{masking}を用いる. whole word maskingとは事前学習時に単語ごとでマスクするかどうかを決め, マスクする単語に対応するサブワードを全てマスクする方式である. モデルのパラメータは次に示す通りである. 
\begin{itemize}
  \item 学習率: 3e-5
  \item エポック数: 10
  \item バッチサイズ: 12
\end{itemize}
実装にはTransformersに含まれるスクリプトであるrun\_squad.pyを用いる. 

\subsection{自動抽出}
前処理したGoogle PlayストアとTwitterのデータから有用な箇所を自動抽出する. 自動抽出にはファインチューニングを行ったモデルとトークン化を行うトークナイザーを使用する. 質問文と抽出対象のデータをトークナイザーでトークン化し, 各トークンをモデルに与えると抽出したキーフレーズとそのキーフレーズの開始位置が返される. 
結果は表\ref{tb:googleqa}に示すようにid, アプリ名, 投稿日時, 文章, 抽出したキーフレーズをcsv形式で保存する. 

\begin{table}[H]
  \caption{Google Playストアレビューの自動抽出結果}
  \label{tb:googleqa}
  \small
  \begin{center}
  \begin{tabularx}{\linewidth}{l|l|X|X|X}
    \hline
    id&アプリ名&投稿日時&元の文章&抽出したキーフレーズ\\\hline\hline
    g\_955&coke\_on&2021-11-27 11:17:03&商品が出ない事が何回か発生しました&商品が出ない\\\hline
    g\_956&coke\_on&2021-11-02 12:15:37&使用している端末が、利用できる端末の一覧表にないため、サポートは期待できない&使用している端末が、利用できる端末の一覧表にない\\\hline
    g\_959&coke\_on&2021-11-11 15:32:50&そもそも自販機側が黄色点滅していなくて買えないことが多過ぎです&自販機側が黄色点滅していなくて買えない\\\hline
    g\_961&coke\_on&2021-11-14 23:13:26&今まではcoke\_on対応を優先してかっていたが、これからはコカコーラ製品全般をできるだけ買わないようにする&今まではcoke\_on対応を優先してかっていたが、これからはコカコーラ製品全般をできるだけ買わないようにする\\\hline
    g\_964&coke\_on&2021-10-24 12:30:07&自販機との接続を早くしてほしい&自販機との接続を早くしてほしい\\\hline
  \end{tabularx}\end{center}
\end{table}

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{クラスタリング}\label{clustering}
\subsection{ベクトルの生成}
抽出した文章をその文章が示す意味に応じてクラスタリングする. クラスタリングするために日本語Sentence-BERTクラスを定義する. 日本語Sentence-BERTクラス (SentenceBertJapanese) の各関数の概要を示す. 
\begin{itemize}
  \item \_\_init\_\_関数 : モデルとトークナイザーの初期化を行う
  \item \_mean\_pooling関数 : モデルの出力とAttention Maskを用いて, 文の埋め込みを生成するための平均プーリングを行う
  \item encode関数 : 文のリストから各文章の埋め込みを求める
\end{itemize}

このように, 日本語BERT用にファインチューニングしたBERTを用いて各トークンの埋め込みを求め, 平均を取ることにより文全体の埋め込みを求めている. 

% \begin{lstlisting}[caption=clustering.py,label=sentence-bert]
%   class SentenceBertJapanese:
%     def __init__ (self, model_name_or_path, device=None) :
%         self.tokenizer = BertJapaneseTokenizer.from_pretrained (model_name_or_path) 
%         self.model = BertModel.from_pretrained (model_name_or_path) 
%         self.model.eval () 

%         if device is None:
%             device = "cuda" if torch.cuda.is_available ()  else "cpu"
%         self.device = torch.device (device) 
%         self.model.to (device) 

%     def _mean_pooling (self, model_output, attention_mask) :
%         token_embeddings = model_output[0] #First element of model_output contains all token embeddings
%         input_mask_expanded = attention_mask.unsqueeze (-1) .expand (token_embeddings.size () ) .float () 
%         return torch.sum (token_embeddings * input_mask_expanded, 1)  / torch.clamp (input_mask_expanded.sum (1) , min=1e-9) 

%     @torch.no_grad () 
%     def encode (self, sentences, batch_size=8) :
%         all_embeddings = []
%         iterator = range (0, len (sentences) , batch_size) 
%         for batch_idx in iterator:
%             batch = sentences[batch_idx:batch_idx + batch_size]

%             encoded_input = self.tokenizer.batch_encode_plus (batch, padding="longest", 
%                                            truncation=True, return_tensors="pt") .to (self.device) 
%             model_output = self.model (**encoded_input) 
%             sentence_embeddings = self._mean_pooling (model_output, encoded_input["attention_mask"]) .to ('cpu') 

%             all_embeddings.extend (sentence_embeddings) 

%         # return torch.stack (all_embeddings) .numpy () 
%         return torch.stack (all_embeddings) 
% \end{lstlisting}

SentenceBertJapaneseクラスの引数に日本語モデル名を与えることによりインスタンスが生成され, モデルの読み込みが完了する. このインスタンスを使用して抽出されたキーフレーズをベクトルに変換する. 

% \begin{lstlisting}[caption=clustering.py,label=model]
%   model = SentenceBertJapanese ("sonoisa/sentence-bert-base-ja-mean-tokens") 
% \end{lstlisting}

\subsection{グラフクラスタリング}
次に, それぞれの抽出したキーフレーズをノード, ノードのベクトル間のコサイン類似度をエッジとする無向グラフを作成する. グラフの作成にはcreate\_graph関数を使用する. 引数には文書埋め込み, 閾値, 生成されたキーフレーズのベクトルを渡す. 

作成されたグラフからChinese Whispersによりグラフクラスタリングが実行される. 作成したクラスタリングに関するcw関数はソースコード\ref{cw}に示す. 

\begin{lstlisting}[caption=cw関数,label=cw]
  def cw (input_csv_file, category, app_name) :
    sentences = create_review_list (input_csv_file, app_name) 
    sentence_vectors = model.encode (sentences) 
    domain_docs = {f'{app_name}': sentences}
    threshold = 0.8
    clusters = []
    
    doc_embeddings = compute_embeddings (domain_docs) 
    G = create_graph (doc_embeddings, threshold, sentence_vectors) 
    # Perform clustering of G, parameters weighting and seed can be omitted
    chinese_whispers (G, weighting='top', iterations=20) 
    for node in G.nodes () :
        text = str (G.nodes[node]['text']) 
        label = int (G.nodes[node]['label']) 
        clusters.append ([text, label]) 
\end{lstlisting}

この関数は次に示す手順で実行される. 

\begin{enumerate}
  \item モデルを使用して文のベクトル表現 (sentence\_vectors) を生成 (3行目) 
  \item Chinese Wispersで使用される閾値 (threshold) , 抽出したキーフレーズとクラスター番号を格納する2次元配列 (clusters) を用意 (5, 6行目)
  \item 文の埋め込み, 閾値, 文のベクトル表現を与えてグラフを作成 (9行目)
  \item chinese\_whispers関数の引数に作成されたグラフ, エッジの重み付けを決定する方法, Chinese Whisperアルゴリズムの反復回数を与えて実行
  \item chinese\_whispers関数の実行によりグラフの各ノードに抽出されたキーフレーズ (text) とクラスター番号 (label) が格納されているためfor文で各情報をclusterに格納していく (12行目〜15行目)
\end{enumerate}

本研究ではエッジの重み付けを決定する方法はデフォルトのtop (エッジの重みをそのまま使用する方法) にし, エッジの最大トークンが重みとして使用される. また, 反復回数は20とした. 

クラスタリングした結果, それぞれの文章にクラスターの番号 (以下 : クラスター番号) が振られる. クラスター番号が同じものが同じクラスターとなり, クラスター番号が近いものは意味的相関が近いことを表す. コサイン類似度の閾値を決めることによりどの程度の類似文を同じクラスターと定義するのかが決定される. 
結果はcsvファイルに保存される. 表\ref{tb:clustering}に示されるように抽出したキーフレーズにそれぞれクラスター番号が振られる. 

\begin{table}[H]
  \caption{抽出したキーフレーズとクラスター番号 (google\_fit) }
  \label{tb:clustering}
  \begin{center}
  \begin{tabularx}{\linewidth}{X|c}
    \hline
    抽出したキーフレーズ&cluster\\\hline\hline
    再起動しても直らない&275\\\hline
    接続/連携を適宜確認しておく必要がある&276\\\hline
    歩いた歩数より足りない&279\\\hline
    使えない&280\\\hline
    使えない&280\\\hline
    歩けない&280\\\hline
    使えない&280\\\hline
    動かなかった&280\\\hline
    反応しない&280\\\hline
    使い方も分からない&280\\\hline
    使えない&280\\\hline
    使えない&280\\\hline
    動かなくなった&280\\\hline
    長期放置されてるんでしょうか&281\\\hline
    下がるって何故でしょうか&282\\\hline
    カウントされなくなる&283\\\hline
    何もカウントしなくなった&283\\\hline
    カウント出来ていない&283\\\hline
    カウントされず&283\\\hline
    記録ができませんと&283\\\hline
  \end{tabularx}\end{center}
\end{table}

\subsection{クラスター名称}
KeyBERTのキーワード抽出によりクラスター名称を決定する手法について説明する. 作成したkeybert関数をソースコード\ref{keybert}に示す. 

\begin{lstlisting}[caption=keybert関数, label=keybert]
  # spaCyの初期化（日本語モデルを使用）
  nlp = spacy.load ('ja_ginza') 

  # 日本語BERTモデルの読み込み
  keybertmodel = SentenceTransformer ('cl-tohoku/bert-base-japanese') 
  keybert_model = KeyBERT (model=keybertmodel) 

  def keybert (text) :
    # spaCyを使用して名詞, 固有名詞, 動詞, 形容詞, 数詞を抽出
    doc = nlp (text) 
    tokens = [token.text for token in doc if token.pos_ == 'NOUN' or token.pos_ == 'PROPN' or token.pos_ == 'ADJ' or token.pos_ == 'NUM' or token.pos_ == 'VERB']
    # tokensをKeyBERTに渡してキーワード抽出
    tokens_text = ' '.join (tokens) 
    keywords = keybert_model.extract_keywords (tokens_text, top_n = 3, keyphrase_ngram_range= (1, 1) , stop_words=None) 
    title = ""
    for title_word in keywords:
        title = title + "【" + title_word[0] + "】 "
    return title
\end{lstlisting}

この関数は次に示す手順で実行される. 

\begin{enumerate}
  \item クラスターの各キーフレーズを結合した1つの大きな文書 (text)をトークン化する (10行目)
  \item トークンのうち名詞, 固有名詞, 動詞, 形容詞, 数詞のみを含む配列を作成 (11行目)
  \item この配列を' ' (空白) で結合し, 新たな文書を生成 (13行目)
  \item KeyBERTモデルのインスタンスからキーワードを抽出するメソッド (extract\_keywords) を呼び出し, キーワードを配列で取得. メソッドの引数には抽出対象となる文書, 抽出するキーワードの数, キーワードの長さを与える. (14行目)
  \item キーワードからタイトルを生成し, 返す (15行目〜18行目)
\end{enumerate}

クラスターの名称が決定したら, クラスター番号とクラスター名称の組み合わせを格納したcsvファイルを作成する. 

%ーーーーーーーーーーーーーーーーーーーーーーーーーーーー

\section{画面出力・可視化}\label{display}
\subsection{使用した言語・フレームワーク}
Webアプリケーションの実装に使用した言語, フレームワークは次に示す通りである. 
\begin{itemize}
    \item フロントエンド: HTML/CSS, JavaScript
    \item バックエンド: Python
    \item フレームワーク: Flask
\end{itemize}

\subsection{概要}
レビューを抽出, クラスタリングした結果を開発者が分析しやすくするためにwebサイト上で表示する. 表示する際は適切な2種類のグラフを用いているため, レビュー内容が把握しやすくなっている. また, 期間やキーワードで検索できるような機能を入れているためレビューを条件に応じて絞り込むことができる. 

\subsection{画面構成}
画面は大きく分けて一覧画面とアプリごとの詳細画面の2つからなる. 

一覧画面では次に示す項目や機能を表示, 付与する. 

\begin{itemize}
  \item 期間, キーワードで絞り込める検索機能の付与
  \item 全てのアプリに対する日ごとのレビュー数を表す折れ線グラフ (Google Playストアのレビューとツイートそれぞれについて)
\end{itemize}

アプリごとの詳細画面では, 次に示す項目や機能を表示, 付与する.

\begin{itemize}
  \item 期間, キーワードで絞り込める検索機能の付与
  \item アコーディオンメニューを使用して抽出した文章の一覧をクラスターごとに表示
  \item 抽出した文章をクリックすると投稿日時や元のレビューがモーダルウィンドウで表示
  \item 日ごとのレビュー数を表す折れ線グラフの表示
  \item クラスターに含まれるレビュー数の上位10個を表す棒グラフの表示
\end{itemize}

アプリの修正や機能の追加などを行った際に, ユーザがアプリの変更に対してどのような内容のレビューを挙げているか, レビュー数に変化があるかどうかを確認することはアプリの開発にとって非常に重要であると考えられる. 
したがって, このwebサイトでは日ごとのレビュー数を表す折れ線グラフや, クラスターに含まれるレビュー数の上位10個を表す棒グラフを表示している. 
また, 特定の機能や期間に関するレビューだけを確認したい際には検索機能を使用してレビューを絞り込むことができる. 
これらの機能によって膨大な数があるレビューを開発者が確認する負担を軽減し, 効率を向上させることができる. 

google fitのレビュー一覧の表示が図\ref{fig:review_items}である. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]
    {contents/images/review_items.png}
  \caption{google fitのレビュー一覧\label{fig:review_items}}
\end{figure}

この一覧はクラスターに含まれるレビュー数が多いものから順に表示されており, ページネーションにより1つのページでレビュー100件ごとに表示している. 
初期状態では, クラスターのタイトルのみ表示されており, タイトルをクリックするとアコーディオンメニューが開き, そのクラスターに属するレビューの一覧が表示される. アコーディオンメニュー内では投稿された日付と抽出されたキーフレーズのみ表示されるが, 抽出されたキーフレーズをクリックすると投稿日時, レビューの全文, 抽出した文章がモーダルで表示される (図\ref{fig:modal}). 
クラスターごとに表示し, 類似したレビューをまとめることで開発者がレビューを確認する効率を上げることができる. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]
    {contents/images/modal.png}
  \caption{レビューのモーダル表示\label{fig:modal}}
\end{figure}

\subsection{検索のロジック}
検索項目である期間とキーワードを指定するとその情報がバックエンド側に渡され, 処理することでリストを更新する. 更新されたリストの情報をフロント側に渡すことで検索結果が反映される. 
ツイートのリストを検索結果に応じて更新するソースコード\ref{search}を示す. 

\begin{lstlisting}[caption=view.py, label=search]
  # ファイル読み込み, 日付でソートしたリスト作成
  with open ('該当アプリのcsvファイルの相対パス', 'r', encoding='utf-8-sig')  as csv_file:
      csv_reader = csv.reader (csv_file) 
      rows = list (csv_reader) 
      rows = sorted (rows, reverse=False, key=lambda x:x[2]) 

  # 検索結果のリスト作成
  search_result = []
  for row in rows:
      if start_date <= row[2][:10] <= end_date:
          if keyword != "":
              if keyword in row[3]:
                  search_result.append (row) 
          else:
              search_result.append (row) 
  rows = search_result
\end{lstlisting}

このコードは次に示す手順で実行される. 

\begin{enumerate}
  \item 抽出, クラスタリングが行われた結果を格納したcsvファイルを開き, リスト形式に変換する (1行目〜5行目)
  \item 各レビューの投稿期間が検索で指定した期間の範囲内にあるかどうかを確認する (10行目)
  \item 検索で指定したキーワードがないなら, そのまま検索結果を格納するリスト (search\_list) に格納する(11, 14, 15行目)
  \item 検索で指定したキーワードがある場合, レビューがそのキーワードを含む場合は検索結果を格納するリスト (search\_list) に格納する (11行目〜13行目)
\end{enumerate}

\subsection{グラフの作成}
グラフの作成にはplotly.jsを用いる. plotly.jsとはグラフ生成ライブラリであり, 3Dグラフや統計グラフなど40を超えるグラフタイプが同梱されている\cite{plotly}.
plotly.jsで作成されたグラフにはオプションとしてズーム機能やグラフのダウンロード機能が付随している. 
日付ごとのレビュー数に関するグラフを表示するソースコード\ref{graph}を示す. 

\begin{lstlisting}[caption=detail.html, label=graph]
  <div class="graph-title">日付ごとのレビュー数の推移</div>
  <div id="scatter"></div>

  <script>
      // 横軸: 日付
      var labels = JSON.parse ('{{ graphs | map (attribute=0)  | list | tojson | safe }}') ;
      // ラベル用日付
      var displayLabels = [];
      for  (var i = 0; i < labels.length; i += 5)  {
          displayLabels.push (labels[i]) ;
      }
      var values = JSON.parse ('{{ graphs | map (attribute=1)  | list | tojson | safe }}') ;

      var data = [{
          x: labels,
          y: values,
          type: 'scatter',
      }];

      var layout = {
          title: '日付ごとのレビュー数の推移',
          height: 600,
          width: 1200,
          xaxis: {
              tickvals: displayLabels,  // 配列の5つおきの目盛り位置を指定
          }
      };

      Plotly.newPlot ('scatter', data, layout) ;
  </script>
\end{lstlisting}

このコードは次に示す構造となっている. 
ここでgraphsはレビューが投稿された日付とその日のレビュー数が格納された二次元リストである. この二次元リストはバックエンド側で作成される. 
横軸にレビューが投稿された日付, 縦軸にレビュー数を取るグラフである. 
dataのtypeでグラフタイプを指定でき, layoutでタイトルや表の大きさを指定できる. 

\begin{itemize}
  \item DOMのターゲットを設定する (2行目)
  \item graphsからレビューが投稿された日付を取得し, 配列 (labels) を生成する (6行目)
  \item グラフの横軸に表示する日付のみを格納したリスト (displayLabels) を生成する (8行目〜11行目)
  \item graphsから日付ごとのレビュー数を取得し, 配列 (values) を生成する (12行目)
  \item 横軸に日付, 縦軸にその日付に投稿されたレビュー数を表示する折れ線グラフを生成するための変数 (data) を宣言する (14行目〜18行目)
  \item タイトルやグラフのサイズ, 横軸に表示する内容を指定するための変数 (layout) を宣言する (20行目〜27行目)
  \item JavaScriptのPlotlyライブラリにあるnewPlotメソッドでグラフを生成する. 引数には, DOMのターゲットのid, 宣言済みのdata, layoutを渡す (20行目〜27行目)
\end{itemize}

ソースコード\ref{graph}によって作成されたグラフが図\ref{fig:majica_graph}である. このグラフは, majicaのレビューにおける日付とレビュー数の関係を表した折れ線グラフである. 
横軸がレビューが投稿された日付, 縦軸がレビュー数をそれぞれ表している. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.4]
    {contents/images/majica_graph.png}
  \caption{majicaのレビューにおける日付とレビュー数の関係\label{fig:majica_graph}}
\end{figure}

このグラフを閲覧することでいつ多くのレビューが挙げられているかどうか確認することができる. また, 検索結果に対応してグラフの日付やレビュー数が変更されるようになっている. 
図\ref{fig:majica_graph}より, majicaのレビューは11月25日に多くのレビューが挙げられていることがわかる. そして11月25日のレビューの内容を詳細画面で確認すると, ``更新したらアプリが開けない'', ``更新してから開けなくなりました''といったアプリの更新によるアプリの不具合が多く報告されていることがわかった. 
このレビューをもとに開発者は更新の内容や起動時のコードなどを確認し, 早急に修正を行うと考えられる. 

クラスターに含まれるレビュー数の上位10個を表す棒グラフが図\ref{fig:top10}である. 横軸がクラスターのタイトル, 縦軸がレビュー数をそれぞれ表している. 
このグラフはgoogle fitにおけるクラスターのうちレビュー数が多いものを10個表示している. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.4]
    {contents/images/top10.png}
  \caption{google fitのレビューにおける種類ごとのレビュー数\label{fig:top10}}
\end{figure}

このグラフを確認すると, インストールやログインに関する不具合や歩数が減少してしまう不具合を報告するレビューが多いことがわかる. このように1つ1つのレビューを確認しなくてもどのような内容のレビューが多く投稿されているのかが可視化されている. 
そして, このグラフも検索結果に対応して, 各クラスターに含まれるレビュー数が変更されるようになっている. 
